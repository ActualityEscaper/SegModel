#ifdef USE_CUDNN
#include <algorithm>
#include <vector>

#include "caffe/layers/cudnn_parallel_conv_layer.hpp"

namespace caffe {


#define CUDNN_STREAMS 2

template <typename Dtype>
vector<cudnnHandle_t*> CuDNNParallelConvolutionLayer<Dtype>::parallel_handle_;
template <typename Dtype>
vector<cudaStream_t*>  CuDNNParallelConvolutionLayer<Dtype>::parallel_stream_;
template <typename Dtype>
vector<void *> CuDNNParallelConvolutionLayer<Dtype>::parallel_workspaceData;
template <typename Dtype>
vector<Blob<Dtype>* > CuDNNParallelConvolutionLayer<Dtype>::parallel_blobs_;

template <typename Dtype>
size_t CuDNNParallelConvolutionLayer<Dtype>::workspaceSizeInBytes = 0; 

template <typename Dtype>
Blob<Dtype>* CuDNNParallelConvolutionLayer<Dtype>::buffer_w = NULL;


template <typename Dtype>
void CuDNNParallelConvolutionLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{
	LOG(INFO)<<"---------------0 --------------------";
	ConvolutionLayer<Dtype>::LayerSetUp(bottom,top);
	
	LOG(INFO)<<"---------------1 --------------------";
//-------------------------------------------------------------------------------- 	
	if (parallel_blobs_.size() == 0)
	{
		parallel_blobs_.resize(bottom.size());
		for(int i=0;i<bottom.size();i++)
		  parallel_blobs_[i]=new Blob<Dtype>();
		  
		buffer_w =new Blob<Dtype>();
		
		for(int i=0;i<bottom.size();i++)
			parallel_workspaceData[i] = NULL;
		
  		
  	parallel_stream_.resize(bottom.size());
	 	parallel_handle_.resize(bottom.size());
	 	parallel_workspaceData.resize(bottom.size());
		for(int i=0;i<bottom.size();i++)
		{
			CUDA_CHECK(cudaSetDevice(Caffe::GPUs[i]));
		
			parallel_stream_[i]         = new cudaStream_t[ CUDNN_STREAMS];
			parallel_handle_[i]         = new cudnnHandle_t[ CUDNN_STREAMS];
			for (int g = 0; g <  CUDNN_STREAMS; g++) 
			{
				CUDA_CHECK(cudaStreamCreate(&parallel_stream_[i][g]));
				CUDNN_CHECK(cudnnCreate(&parallel_handle_[i][g]));
				CUDNN_CHECK(cudnnSetStream(parallel_handle_[i][g], parallel_stream_[i][g]));
			}
		}	
		CUDA_CHECK(cudaSetDevice(Caffe::GPUs[0]));		
  }  
//--------------------------------------------------------------------------------  
	LOG(INFO)<<"---------------2 --------------------";
	
	
	parallel_workspace.resize(bottom.size());
	for(int i=0;i<bottom.size();i++)
  		parallel_workspace[i] = new void*[ CUDNN_STREAMS];

	cudnn::createFilterDesc<Dtype>(&filter_desc_,
	    this->num_output_ , this->channels_, this->kernel_size_, this->kernel_size_);


  cudnnTensorDescriptor_t bottom_desc_;
  cudnn::createTensor4dDesc<Dtype>(&bottom_desc_);

  cudnnTensorDescriptor_t top_desc_;
  cudnn::createTensor4dDesc<Dtype>(&top_desc_);
  
  cudnnConvolutionDescriptor_t conv_desc_;
  cudnn::createConvolutionDesc<Dtype>(&conv_desc_);
 
  
  handles_setup_ = true;    
}

template <typename Dtype>
void CuDNNParallelConvolutionLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{
	ConvolutionLayer<Dtype>::Reshape(bottom, top);
	for (int i=1;i<top.size();i++)
		top[i]->ReshapeLike(*top[0]);
		
	for(int i=0;i<bottom.size();i++)
		parallel_blobs_[i]->ReshapeLike(*this->blobs_[0]);

  buffer_w->ReshapeLike(*this->blobs_[0]);

	
	
  const int num = bottom[0]->num();
  const int height = bottom[0]->height();
  const int width = bottom[0]->width();
  const int height_out = top[0]->height();
  const int width_out = top[0]->width();


  cudnn::setTensor4dDesc<Dtype>(&bottom_descs_,
      num, this->channels_ , height, width);
  cudnn::setTensor4dDesc<Dtype>(&top_descs_,
      num, this->num_output_ , height_out, width_out);  
  cudnn::setConvolutionDesc<Dtype>(&conv_descs_, 
      this->pad_, this->pad_, this->stride_, this->stride_);
  

  size_t workspace_limit_bytes = 0;
  for (int i = 0; i < bottom.size(); i++) 
  {
    CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(parallel_handle_[0][0],
				  bottom_descs_,
				  filter_desc_,
				  conv_descs_,
				  top_descs_,
				  CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,
				  workspace_limit_bytes,
				  &fwd_algo_));
    CUDNN_CHECK(cudnnGetConvolutionBackwardFilterAlgorithm(parallel_handle_[0][0],
          bottom_descs_, 
          top_descs_, 
          conv_descs_, 
          filter_desc_,
          CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST,
          workspace_limit_bytes, 
          &bwd_filter_algo_) );
    CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(parallel_handle_[0][0],
          filter_desc_, 
          top_descs_, 
          conv_descs_, 
          bottom_descs_,
          CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST,
          workspace_limit_bytes, 
          &bwd_data_algo_));
		
		
		CUDNN_CHECK(cudnnGetConvolutionForwardWorkspaceSize(parallel_handle_[0][0],
				  bottom_descs_,
				  filter_desc_,
				  conv_descs_,
				  top_descs_,
				  fwd_algo_,
				  &(workspace_fwd_sizes_)));
    CUDNN_CHECK(cudnnGetConvolutionBackwardFilterWorkspaceSize(parallel_handle_[0][0],
          bottom_descs_, 
          top_descs_, 
          conv_descs_, 
          filter_desc_,
          bwd_filter_algo_, 
          &workspace_bwd_filter_sizes_));
    CUDNN_CHECK(cudnnGetConvolutionBackwardDataWorkspaceSize(parallel_handle_[0][0],
          filter_desc_, 
          top_descs_, 
          conv_descs_, 
          bottom_descs_,
          bwd_data_algo_, 
          &workspace_bwd_data_sizes_));
  }
  
 
  size_t max_workspace = 0;

  max_workspace = std::max(max_workspace, workspace_fwd_sizes_);
  max_workspace = std::max(max_workspace, workspace_bwd_data_sizes_);
  max_workspace = std::max(max_workspace, workspace_bwd_filter_sizes_);
  
  size_t total_max_workspace = max_workspace * CUDNN_STREAMS;
  if (total_max_workspace > workspaceSizeInBytes) 
  {
    DLOG(INFO) << "Reallocating workspace storage: " << total_max_workspace;
    workspaceSizeInBytes = total_max_workspace;

    for (int i = 0; i < bottom.size(); i++) 
 		{
 			CUDA_CHECK(cudaSetDevice(Caffe::GPUs[i]));
		  cudaFree(this->parallel_workspaceData[i]);
		  
		  CUDA_CHECK(cudaMalloc(&(this->parallel_workspaceData[i]), workspaceSizeInBytes));		  
		  for (int g = 0; g <  CUDNN_STREAMS; g++) 
		    parallel_workspace[i][g] = reinterpret_cast<char *>(parallel_workspaceData[i]) + g*max_workspace;
		}   
		CUDA_CHECK(cudaSetDevice(Caffe::GPUs[0])); 			
  } 
}
template <typename Dtype>
void CuDNNParallelConvolutionLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top)
{}
template <typename Dtype>
void CuDNNParallelConvolutionLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,  const vector<Blob<Dtype>*>& bottom)
{}
template <typename Dtype>
CuDNNParallelConvolutionLayer<Dtype>::~CuDNNParallelConvolutionLayer() 
{

  if (!handles_setup_) { return; }


  cudnnDestroyTensorDescriptor(bottom_descs_);
  cudnnDestroyTensorDescriptor(top_descs_);
  cudnnDestroyConvolutionDescriptor(conv_descs_);
  
	cudnnDestroyFilterDescriptor(filter_desc_);

	
//----------------------------------------------------------------------	
	if (parallel_stream_.size() != 0)
	{
		for (int i = 0; i < parallel_stream_.size(); i++) 
		{
			for (int g = 0; g < CUDNN_STREAMS; g++) 
			{
				cudaStreamDestroy(parallel_stream_[i][g]);
				cudnnDestroy(parallel_handle_[i][g]);
			}
		}  
		parallel_stream_.clear();
		for (int i = 0; i < parallel_stream_.size(); i++) 
		{
			delete parallel_stream_[i];
			delete parallel_handle_[i];
		}	
		parallel_stream_.clear();
		parallel_handle_.clear();
		
		for (int i = 0; i < parallel_stream_.size(); i++) 
			cudaFree(parallel_workspaceData[i]);
		parallel_workspaceData.clear();
		delete buffer_w;
	
		
		for (int i=0;i<parallel_blobs_.size();i++)
		 delete parallel_blobs_[i];
		parallel_blobs_.clear(); 
	}
//----------------------------------------------------------------------			
}

INSTANTIATE_CLASS(CuDNNParallelConvolutionLayer);
REGISTER_LAYER_CLASS(CuDNNParallelConvolution);
}   // namespace caffe
#endif
