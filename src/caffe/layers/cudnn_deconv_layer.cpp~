#ifdef USE_CUDNN
#include <algorithm>
#include <vector>

#include "caffe/layers/cudnn_deconv_layer.hpp"

namespace caffe {

#define CUDNN_STREAMS 1

template <typename Dtype>
cudnnHandle_t* CuDNNDeConvolutionLayer<Dtype>::handle_ = NULL;
template <typename Dtype>
cudaStream_t*  CuDNNDeConvolutionLayer<Dtype>::stream_ = NULL;

template <typename Dtype>
void * CuDNNDeConvolutionLayer<Dtype>::workspaceData = NULL;
template <typename Dtype>
size_t CuDNNDeConvolutionLayer<Dtype>::workspaceSizeInBytes = 0;

template <typename Dtype>
void CuDNNDeConvolutionLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{

  DeConvolutionLayer<Dtype>::LayerSetUp(bottom, top);
//--------------------------------------------------------------------------------   
  // Initialize CUDA streams and cuDNN.
  if (stream_ == NULL)
  {
		stream_         = new cudaStream_t[ CUDNN_STREAMS];
		handle_         = new cudnnHandle_t[ CUDNN_STREAMS];
		
		for (int g = 0; g <  CUDNN_STREAMS; g++) 
  	{
		  CUDA_CHECK(cudaStreamCreate(&stream_[g]));
		  CUDNN_CHECK(cudnnCreate(&handle_[g]));
		  CUDNN_CHECK(cudnnSetStream(handle_[g], stream_[g]));   
  	}
	}
//-------------------------------------------------------------------------------- 	

  // workspace data
  workspace = new void*[ CUDNN_STREAMS];

  


  // Create filter descriptor.
  if (this->group_ == 1)
 	{
		cudnn::createFilterDesc<Dtype>(&filter_desc_,
		    this->num_output_ , this->channels_, this->kernel_size_, this->kernel_size_);
  }
  else
  {
  	cudnn::createFilterDesc<Dtype>(&filter_desc_,
		    1 , 1, this->kernel_size_, this->kernel_size_);
  }
      
      
	// Tensor descriptor for bias.
  if (this->layer_param_.convolution_param().bias_term()) 
  {
    cudnn::createTensor4dDesc<Dtype>(&bias_desc_);
    cudnn::setTensor4dDesc<Dtype>(&bias_desc_,
        1, this->num_output_, 1, 1); 
  }



 

  cudnn::createTensor4dDesc<Dtype>(&bottom_descs_);
  cudnn::createTensor4dDesc<Dtype>(&top_descs_);
  cudnn::createConvolutionDesc<Dtype>(&conv_descs_);

 
  handles_setup_ = true;        
}

template <typename Dtype>
void CuDNNDeConvolutionLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{
  DeConvolutionLayer<Dtype>::Reshape(bottom, top);

  const int num = bottom[0]->num();
  const int height = bottom[0]->height();
  const int width = bottom[0]->width();
  const int height_out = top[0]->height();
  const int width_out = top[0]->width();


  //we alays choose the fastest algorithm or the zero momory cost version
  //size_t workspace_limit_bytes = 0;
	size_t workspace_limit_bytes = 0;
  if (this->group_ == 1)
 	{
		cudnn::setTensor4dDesc<Dtype>(&bottom_descs_,
		    num, this->channels_ , height, width);
		cudnn::setTensor4dDesc<Dtype>(&top_descs_,
		    num, this->num_output_ , height_out, width_out);  
		cudnn::setConvolutionDesc<Dtype>(&conv_descs_, 
		    this->pad_, this->pad_, this->stride_, this->stride_);
	}
	else
	{
		cudnn::setTensor4dDesc<Dtype>(&bottom_descs_,
		    1, 1 , height, width);
		cudnn::setTensor4dDesc<Dtype>(&top_descs_,
		    1, 1 , height_out, width_out);  
		cudnn::setConvolutionDesc<Dtype>(&conv_descs_, 
		    this->pad_, this->pad_, this->stride_, this->stride_);
	}

// choose forward and backward algorithms + workspace(s)
	if (false)//(num > 1)
	{
		CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(handle_[0],
		    filter_desc_, 
		    top_descs_, 
		    conv_descs_, 
		    bottom_descs_,
		    CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST,
		    workspace_limit_bytes, 
		    &bwd_data_algo_));      
		CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(handle_[0],
					bottom_descs_,
					filter_desc_,
					conv_descs_,
					top_descs_,
					CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,
					workspace_limit_bytes,
					&fwd_algo_));			
  }
  else
  {
  	fwd_algo_ = (cudnnConvolutionFwdAlgo_t)0;
		bwd_filter_algo_ = (cudnnConvolutionBwdFilterAlgo_t)0;
		bwd_data_algo_ = (cudnnConvolutionBwdDataAlgo_t)0;  
  }    
      
  CUDNN_CHECK(cudnnGetConvolutionBackwardDataWorkspaceSize(handle_[0],
			filter_desc_, 
			bottom_descs_, 
			conv_descs_, 
			top_descs_,
			bwd_data_algo_, 
			&workspace_bwd_data_sizes_) );   
	CUDNN_CHECK(cudnnGetConvolutionForwardWorkspaceSize(handle_[0],
			top_descs_,
			filter_desc_,
			conv_descs_,
			top_descs_,
			fwd_algo_,
			&(workspace_fwd_sizes_)));			   


      
	

  
  
   
  max_workspace = 0;
  
 	max_workspace = std::max(max_workspace, workspace_bwd_data_sizes_);
  max_workspace = std::max(max_workspace, workspace_fwd_sizes_);
  
  
  size_t total_max_workspace = max_workspace * CUDNN_STREAMS;
	
  if (total_max_workspace > workspaceSizeInBytes) 
  {
    LOG(INFO) << "Reallocating workspace storage: " << total_max_workspace;
    workspaceSizeInBytes = total_max_workspace;

    cudaFree(workspaceData);
    CUDA_CHECK(cudaMalloc(&(workspaceData), workspaceSizeInBytes));
  } 
  for (int g = 0; g <  CUDNN_STREAMS; g++) 
    workspace[g] = reinterpret_cast<char *>(workspaceData) + g*max_workspace;      
}
template <typename Dtype>
void CuDNNDeConvolutionLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top)
{}
template <typename Dtype>
void CuDNNDeConvolutionLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,  const vector<Blob<Dtype>*>& bottom)
{}
template <typename Dtype>
CuDNNDeConvolutionLayer<Dtype>::~CuDNNDeConvolutionLayer() 
{
  // Check that handles have been setup before destroying.
  if (!handles_setup_) { return; }

  
  cudnnDestroyTensorDescriptor(bottom_descs_);
  cudnnDestroyTensorDescriptor(top_descs_);
  cudnnDestroyConvolutionDescriptor(conv_descs_);
  
  if (this->layer_param_.convolution_param().bias_term()) 
    cudnnDestroyTensorDescriptor(bias_desc_);

  cudnnDestroyFilterDescriptor(filter_desc_);

	if (stream_ != NULL)
	{
		for (int g = 0; g < CUDNN_STREAMS; g++) 
		{
		  cudaStreamDestroy(stream_[g]);
		  cudnnDestroy(handle_[g]);
		}
		delete [] stream_;
		delete [] handle_;
		stream_ = NULL;
		handle_ = NULL;
	}
	
	if (workspaceData != NULL)
	{
  	CUDA_CHECK(cudaFree(workspaceData));
  	workspaceData = NULL;
  	
  	workspaceSizeInBytes = 0; 
  }	 
}

INSTANTIATE_CLASS(CuDNNDeConvolutionLayer);
REGISTER_LAYER_CLASS(CuDNNDeConvolution);
}   // namespace caffe
#endif
