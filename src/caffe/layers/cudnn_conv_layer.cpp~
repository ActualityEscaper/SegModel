#ifdef USE_CUDNN
#include <algorithm>
#include <vector>

#include "caffe/layers/cudnn_conv_layer.hpp"

namespace caffe {

#define CUDNN_STREAMS 3

template <typename Dtype>
cudnnHandle_t* CuDNNConvolutionLayer<Dtype>::handle_ = NULL;
template <typename Dtype>
cudaStream_t*  CuDNNConvolutionLayer<Dtype>::stream_ = NULL;


template <typename Dtype>
void CuDNNConvolutionLayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{

  ConvolutionLayer<Dtype>::LayerSetUp(bottom, top);

//--------------------------------------------------------------------------------   
  // Initialize CUDA streams and cuDNN.
  if (stream_ == NULL)
  {
		stream_         = new cudaStream_t[ CUDNN_STREAMS];
		handle_         = new cudnnHandle_t[ CUDNN_STREAMS];
		
		for (int g = 0; g <  CUDNN_STREAMS; g++) 
  	{
		  CUDA_CHECK(cudaStreamCreate(&stream_[g]));
		  CUDNN_CHECK(cudnnCreate(&handle_[g]));
		  CUDNN_CHECK(cudnnSetStream(handle_[g], stream_[g]));   
  	}
	}
//-------------------------------------------------------------------------------- 	

  


  // Create filter descriptor.
  cudnn::createFilterDesc<Dtype>(&filter_desc_,
      this->num_output_ , this->channels_, this->kernel_size_, this->kernel_size_);
	// Tensor descriptor for bias.
  if (this->layer_param_.convolution_param().bias_term()) 
  {
    cudnn::createTensor4dDesc<Dtype>(&bias_desc_);
    cudnn::setTensor4dDesc<Dtype>(&bias_desc_,
        1, this->num_output_, 1, 1); 
  }



 

  cudnn::createTensor4dDesc<Dtype>(&bottom_descs_);
  cudnn::createTensor4dDesc<Dtype>(&top_descs_);
  cudnn::createConvolutionDesc<Dtype>(&conv_descs_);

 
  handles_setup_ = true;         
}

template <typename Dtype>
void CuDNNConvolutionLayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{
  ConvolutionLayer<Dtype>::Reshape(bottom, top);

  const int num = bottom[0]->num();
  const int height = bottom[0]->height();
  const int width = bottom[0]->width();
  const int height_out = top[0]->height();
  const int width_out = top[0]->width();



  //set the max work space data in case of RUNOUT of memory
  //take 448 x 448 as a exemplar
	size_t workspace_limit_bytes = 511888000;
	if (num == 1)
		workspace_limit_bytes = 0;
  
  cudnn::setTensor4dDesc<Dtype>(&bottom_descs_,
      num, this->channels_ , height, width);
  cudnn::setTensor4dDesc<Dtype>(&top_descs_,
      num, this->num_output_ , height_out, width_out);  
  cudnn::setConvolutionDesc<Dtype>(&conv_descs_, 
      this->pad_, this->pad_, this->stride_, this->stride_);

#if 0
		CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(handle_[0],
					bottom_descs_,
					filter_desc_,
					conv_descs_,
					top_descs_,
					CUDNN_CONVOLUTION_FWD_PREFER_FASTEST,
					workspace_limit_bytes,
					&fwd_algo_));			
		CUDNN_CHECK(cudnnGetConvolutionBackwardFilterAlgorithm(handle_[0],
		    bottom_descs_, 
		    top_descs_, 
		    conv_descs_, 
		    filter_desc_,
		    CUDNN_CONVOLUTION_BWD_FILTER_PREFER_FASTEST,
		    workspace_limit_bytes, 
		    &bwd_filter_algo_) );
		CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(handle_[0],
		    filter_desc_, 
		    top_descs_, 
		    conv_descs_, 
		    bottom_descs_,
		    CUDNN_CONVOLUTION_BWD_DATA_PREFER_FASTEST,
		    workspace_limit_bytes, 
		    &bwd_data_algo_));      
#endif
  	CUDNN_CHECK(cudnnGetConvolutionForwardAlgorithm(handle_[0],
					bottom_descs_,
					filter_desc_,
					conv_descs_,
					top_descs_,
					CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,
					workspace_limit_bytes,
					&fwd_algo_));			
		CUDNN_CHECK(cudnnGetConvolutionBackwardFilterAlgorithm(handle_[0],
		    bottom_descs_, 
		    top_descs_, 
		    conv_descs_, 
		    filter_desc_,
		    CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT,
		    workspace_limit_bytes, 
		    &bwd_filter_algo_) );
		CUDNN_CHECK(cudnnGetConvolutionBackwardDataAlgorithm(handle_[0],
		    filter_desc_, 
		    top_descs_, 
		    conv_descs_, 
		    bottom_descs_,
		    CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT,
		    workspace_limit_bytes, 
		    &bwd_data_algo_));   
#if 0		               
  	fwd_algo_ = (cudnnConvolutionFwdAlgo_t)0;
		bwd_filter_algo_ = (cudnnConvolutionBwdFilterAlgo_t)0;
		bwd_data_algo_ = (cudnnConvolutionBwdDataAlgo_t)0;     
#endif

   
	CUDNN_CHECK(cudnnGetConvolutionForwardWorkspaceSize(handle_[0],
			bottom_descs_,
			filter_desc_,
			conv_descs_,
			top_descs_,
			fwd_algo_,
			&(workspace_fwd_sizes_)));			   
	CUDNN_CHECK(cudnnGetConvolutionBackwardFilterWorkspaceSize(handle_[0],
		  bottom_descs_, 
		  top_descs_, 
		  conv_descs_, 
		  filter_desc_,
		  bwd_filter_algo_, 
		  &workspace_bwd_filter_sizes_));    
	CUDNN_CHECK(cudnnGetConvolutionBackwardDataWorkspaceSize(handle_[0],
			filter_desc_, 
			top_descs_, 
			conv_descs_, 
			bottom_descs_,
			bwd_data_algo_, 
			&workspace_bwd_data_sizes_) );   

  //LOG(INFO)<<" fwd_algo_ = "<<fwd_algo_ <<" "
 // 					<<" bwd_filter_algo_ ="<<bwd_filter_algo_<<" "
  //					<<" bwd_data_algo_ = "<<bwd_data_algo_;    
	
	 	this->workspace_[0]->Reshape(ceil(workspace_fwd_sizes_/sizeof(Dtype)),1,1,1);
 	this->workspace_[0]->Reshape(ceil(workspace_bwd_data_sizes_/sizeof(Dtype)),1,1,1);
 	this->workspace_[0]->Reshape(ceil(workspace_bwd_filter_sizes_/sizeof(Dtype)),1,1,1);    
  
  
   
       
}
template <typename Dtype>
void CuDNNConvolutionLayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top)
{}
template <typename Dtype>
void CuDNNConvolutionLayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,  const vector<Blob<Dtype>*>& bottom)
{}
template <typename Dtype>
CuDNNConvolutionLayer<Dtype>::~CuDNNConvolutionLayer() 
{
  // Check that handles have been setup before destroying.
  if (!handles_setup_) { return; }

  
  cudnnDestroyTensorDescriptor(bottom_descs_);
  cudnnDestroyTensorDescriptor(top_descs_);
  cudnnDestroyConvolutionDescriptor(conv_descs_);
  
  if (this->layer_param_.convolution_param().bias_term()) 
    cudnnDestroyTensorDescriptor(bias_desc_);

  cudnnDestroyFilterDescriptor(filter_desc_);

	if (stream_ != NULL)
	{
		for (int g = 0; g < CUDNN_STREAMS; g++) 
		{
		  cudaStreamDestroy(stream_[g]);
		  cudnnDestroy(handle_[g]);
		}
		delete [] stream_;
		delete [] handle_;
		stream_ = NULL;
		handle_ = NULL;
	}

}

INSTANTIATE_CLASS(CuDNNConvolutionLayer);
REGISTER_LAYER_CLASS(CuDNNConvolution);
}   // namespace caffe
#endif
