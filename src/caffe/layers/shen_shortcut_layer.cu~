#include <vector>

#include "caffe/layers/shen_shortcut_layer.hpp"
#include "caffe/util/math_functions.hpp"

namespace caffe {


template <typename Dtype>
void ShenShortcutLayer<Dtype>::Forward_gpu(const vector<Blob<Dtype>*>& bottom, const vector<Blob<Dtype>*>& top) 
{	
	this->blobs_[0]->mutable_cpu_data()[0] = std::max(this->blobs_[0]->cpu_data()[0],-Dtype(1)); 
	this->blobs_[0]->mutable_cpu_data()[0] = std::min(this->blobs_[0]->cpu_data()[0],Dtype(1));
	
	multiplier = this->blobs_[0]->cpu_data()[0];
	
	if (Caffe::phase() == TRAIN)
	{	
		caffe_rng_bernoulli(1, Dtype(1. - dropout_ratio_), &mask);
		multiplier = multiplier * mask * 1. / (1. - dropout_ratio_); ; 
	}
	caffe_gpu_add(bottom[0]->count(),Dtype(1),bottom[0]->gpu_data(), multiplier,bottom[1]->gpu_data(),top[0]->mutable_gpu_data());		
}

template <typename Dtype>
void ShenShortcutLayer<Dtype>::Backward_gpu(const vector<Blob<Dtype>*>& top, const vector<Blob<Dtype>*>& bottom) 
{
	lambda->Reshape(bottom[0]->num(), bottom[0]->channels(), bottom[0]->height(), bottom[0]->width());
  all_one->ReshapeLike(*lambda);
  caffe_gpu_set(all_one->count(),Dtype(1.0),all_one->mutable_gpu_data());



	caffe_copy(top[0]->count(),top[0]->gpu_diff(),bottom[1]->mutable_gpu_diff());
	caffe_gpu_scal(bottom[1]->count(), multiplier,bottom[1]->mutable_gpu_diff());
	

	if (mask == 1 && this->lr_mult()[0] != 0)
	{
		caffe_gpu_mul(top[0]->count(),top[0]->gpu_diff(),bottom[1]->gpu_data(),lambda->mutable_gpu_data());
		
		Dtype sum_diff;
		
		caffe_gpu_dot(lambda->count(),lambda->gpu_data(),all_one->gpu_data(),&sum_diff);	
		
		this->blobs_[0]->mutable_cpu_diff()[0] += sum_diff;	
	}		
}

INSTANTIATE_LAYER_GPU_FUNCS(ShenShortcutLayer);
}  // namespace caffe
